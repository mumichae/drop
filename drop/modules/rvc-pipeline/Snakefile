from pathlib import Path

RVC_WORKDIR = cfg.RVC.getWorkdir(str_=False)

RVC_index_name = "rvc-pipeline"
RVC_index_input, RVC_index_output, RVC_graph_file, _ = createIndexRule(
    scriptsPath=str(RVC_WORKDIR),
    index_name=RVC_index_name
)

rule rnaVariantCalling:
    input:
        expand(
            str(RVC_WORKDIR / "{dataset}_alt{minAlt}_done.txt"),
            dataset = cfg.RVC.groups, # As defined by the sample annotation table RNA_VARIANT_GROUPS
            minAlt = cfg.RVC.getMinAlt()
        ),
        RVC_index_input,
        RVC_graph_file
    output: RVC_index_output
    run: ci(str(RVC_WORKDIR), RVC_index_name)

rule rnaVariantCalling_dependency:
    output: RVC_graph_file
    shell: "snakemake --rulegraph {RVC_index_output} | dot -Tsvg -Grankdir=TB > {output}"


#Define the {sample} variable
#create the empty output file of the form: {dataset}_alt{minAlt}_done.txt
rule rnaVariantCalling_allVariants:
    input:
        lambda wildcards: expand(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller", "{sample}",
            "{sample}.genotyped.filtered.basic" + cfg.RVC.getMinAlt() +".masked.vcf.gz"),
            sample = sa.getIDsByGroup(wildcards.dataset,assay = "RVC"))
    output:
        touch(cfg.RVC.getWorkdir(str_=False) / "{dataset}_alt{minAlt}_done.txt")

#Use the repeat_mask bedfile to filter/label variants in repeat regions
rule rnaVariantCalling_masked_singleVCF_filter:
    input: 
        vcf = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + cfg.RVC.getMinAlt() +".vcf.gz"),
        vcf_tabix = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + cfg.RVC.getMinAlt() + ".vcf.gz.tbi"),
        repeat_mask = cfg.RVC.getRepeatMask(sortedName=True)
    output:
        os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + cfg.RVC.getMinAlt() + ".masked.vcf.gz")
    params:
        sample = '{sample}',
        ref = cfg.getFastaFile(),
        outDir = str(cfg.processedDataDir / "rnaVariantCalling/")
    log:
        str(cfg.processedDataDir) + "/logs/sample_haplocaller/" + "{sample}" + "_maskedFilterVariants.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" VariantFiltration -R {params.ref} \
        -V {input.vcf} --mask {input.repeat_mask} -O {output} 2> {log}
        """

rule rnaVariantCalling_sortIndexRepeatMask:
    input:
        repeat_mask = cfg.RVC.getRepeatMask()
    output:
        sorted_repeat_mask = cfg.RVC.getRepeatMask(sortedName = True),
        sorted_index = cfg.RVC.getRepeatMask(sortedName = True) + ".idx"
    shell:
        """
        sort -k1,2 -V {input.repeat_mask} > {output.sorted_repeat_mask}
        gatk IndexFeatureFile -I {output.sorted_repeat_mask}
        """

#Use the minAlt value to filter/label variants that do not have a minimum alternative read support
rule rnaVariantCalling_basic_singleVCF_filter:
    input: 
        vcf = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz"),
        vcf_tabix = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.tbi")
    output:
        vcf = os.path.join(cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + cfg.RVC.getMinAlt() +".vcf.gz"),
        vcf_tbi = os.path.join(cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.basic" + cfg.RVC.getMinAlt() +".vcf.gz.tbi"),
    params:
        sample = '{sample}',
        minAlt = cfg.RVC.getMinAlt(),
        ref = cfg.getFastaFile(),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling"
    log:
        str(cfg.processedDataDir) + "/logs/sample_haplocaller/" + "{sample}" + "_basicFilterVariants.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" VariantFiltration -R {params.ref} \
        -V {input.vcf} --filter-name minAlt --filter-expression "vc.getGenotype('{params.sample}').getAD().1 < {params.minAlt}" -O {output.vcf} 2> {log}
        """


#Use bcftools to split the multi-sample VCF file into a VCF file for the corresponding sample. Normalize the variants to remove artifacts
rule rnaVariantCalling_split_multiVCF:
    input:
        lambda wildcards: os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            cfg.RVC.batchIDs[wildcards.sample] + "_all_samples.genotyped.filtered_clean.vcf.gz")
    params:
        ref = cfg.getFastaFile(),
        sampleID = "{sample}",

    output:
        vcf = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz")),

        vcf_tabix = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.tbi")),
        toDel_split = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.split")),
        toDel_tmp = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.genotyped.filtered.vcf.gz.tmp"))
    log:
        str(cfg.processedDataDir) + "/logs/sample_haplocaller/{sample}.single_vcf.log"
    shell:
        """
        echo "reading multi-sample vcf into single sample vcf"
        bcftools view -c1 -Oz -s {params.sampleID} -o {output.toDel_tmp} {input}
        echo "split multi-line variants into single lines. Remove those that are artifacts"
        bcftools norm -m-both {output.toDel_tmp} > {output.toDel_split}
        echo "remove redundant variant info AAAG>AC == AAG>C and remove empty variant calls"
        bcftools norm -f {params.ref}  {output.toDel_split} |grep -w -v "*"|grep -w -v "0/0" |bgzip -c > {output.vcf}
        tabix -p vcf {output.vcf}
        """


#Use bcftools to left normalize variants. Variants labeled AAAG>AC can be shortened to AAG>C 
rule rnaVariantCalling_leftNormalVCF:
    input:
        os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}" + "_all_samples.genotyped.filtered.split.vcf.gz")
    output:
        os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.genotyped.filtered_clean.vcf.gz")
    params:
        ref = cfg.getFastaFile()
    shell:
        """ 
        bcftools norm -f {params.ref} {input} | bgzip -c > {output}
        tabix -p vcf {output}
         """


#Use bcftools to split VCF with multiple variants on a single line into a VCF with a single variant per line. G>A,C into 2 lines G>A and G>C
rule rnaVariantCalling_splitVCF:
    input:
        ancient(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.genotyped.filtered.vcf.gz"))
    output:
        split_vcf = temp(os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}" + "_all_samples.genotyped.filtered.split.vcf.gz"
            )),
        toDel = temp(os.path.join(
                cfg.processedDataDir,
                "rnaVariantCalling/tmp/",
                "{dataset}" + "_DELETE_ME"))
    shell: 
        """
        bcftools norm -m-both {input} > {output.toDel} 
        grep -v -w "*" {output.toDel} |bgzip -c > {output.split_vcf}
        """


#Use GATK to filter variants based on the quality scores and variant frequency based on the GATK-best practices
rule rnaVariantCalling_filterVCF:
    input:
        os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.genotyped.vcf.gz")
    output:
        filt_vcf = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.genotyped.filtered.vcf.gz"
        )),
        filt_vcf_tbi = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.genotyped.filtered.vcf.gz.tbi"))
    params:
        ref = cfg.getFastaFile(),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling"
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{dataset}_filterVariants.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" VariantFiltration -R {params.ref} -V {input} \
        -window 35 -cluster 3 --filter-name FS --filter-expression "FS > 30.0" \
        --filter-name QD --filter-expression "QD < 2.0" -O {output.filt_vcf} 2> {log}
        """


#Using GATK GenotypeGVCFs to make the variant calls from the combined g.vcf files
rule rnaVariantCalling_genotypeGVCFs:
    input:
        gvcf = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.g.vcf.gz"),

        gvcf_tbi = os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.g.vcf.gz.tbi")
    output:
        os.path.join( cfg.processedDataDir,
            "rnaVariantCalling/out/all_samples_haplocaller",
            "{dataset}_all_samples.genotyped.vcf.gz")
    params:
        ref = cfg.getFastaFile(),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling"
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{dataset}_genotypeGVCFs.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" GenotypeGVCFs -R {params.ref} \
        --variant {input.gvcf} -O {output} 2> {log}
        """


#Using GATK combine the vcfs from each sample within a {dataset} into a multi-sample vcf file to improve genotyping and variant calls
rule rnaVariantCalling_combineGVCFs:
    input:
        lambda wildcards: expand(
            os.path.join(
            cfg.processedDataDir,
            "rnaVariantCalling/out/sample_haplocaller",
            "{sample}",
            "{sample}.g.vcf.gz" 
            ), sample = sa.getIDsByGroup(wildcards.dataset,assay = "RVC"))
    output:
        gvcf = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.g.vcf.gz"
        )),

        gvcf_tbi = temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/all_samples_haplocaller",
        "{dataset}_all_samples.g.vcf.gz.tbi"))
    params:
        ref = cfg.getFastaFile(),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling",
        variant_list = lambda wildcards: ["--variant " + i for i in expand(
                os.path.join(
                cfg.processedDataDir,
                "rnaVariantCalling/out/sample_haplocaller",
                "{sample}",
                "{sample}.g.vcf.gz" ), sample = sa.getIDsByGroup(wildcards.dataset,assay = "RVC"))]
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{dataset}_combineGVCF.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" CombineGVCFs -R {params.ref} \
        {params.variant_list} -O {output.gvcf} 2> {log}
        """


#Using GATK HaplotypeCaller take the cleaned and recalibrated BAM file as input for the variant calling.
rule rnaVariantCalling_haplotypeCaller:
    input:
        bam = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.bqsr.out.bam")
    output:
        os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/sample_haplocaller",
        "{sample}",
        "{sample}.g.vcf.gz")
    params:
        ref = cfg.getFastaFile(),
        hcArgs = cfg.RVC.get("hcArgs"),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling"
    log:
        str(cfg.processedDataDir) + "/logs/all_haplocaller/{sample}.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" HaplotypeCaller -R {params.ref} -I {input.bam} \
        --dont-use-soft-clipped-bases -stand-call-conf 20.0 \
        --output-mode EMIT_ALL_CONFIDENT_SITES \
        -ERC GVCF {params.hcArgs} -O {output} 2> {log}
        """


#Using GATK ApplyBQSR takes the frequency table and confidence scores generated by BQSR and recalculates the BAM quality scores
rule rnaVariantCalling_applyBQSR:
    input:
        bam = os.path.join(
        cfg.processedDataDir, 
        "rnaVariantCalling/out/bam", 
        "{sample}", 
        "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bam"
        ),
        table = os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bqsr/{sample}_recal.table")
    output:
        temp(os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bam",
        "{sample}",
        "{sample}_Aligned.sortedByCoord.dupMarked.split.bqsr.out.bam"))
    params:
        ref = cfg.getFastaFile(),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling"
    log:
        str(cfg.processedDataDir) + "/logs/applyBQSR/{sample}.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" ApplyBQSR  \
        -R {params.ref} -I {input.bam} --bqsr-recal-file {input.table} \
        --add-output-sam-program-record --use-original-qualities -O {output} 2> {log}
        """


#Using GATK BaseRecalibrator (BQSR) use the known sites (dbSNP + others) to improve read scoring
rule rnaVariantCalling_bqsr:
    input:
        os.path.join(
        cfg.processedDataDir, 
        "rnaVariantCalling/out/bam", 
        "{sample}", 
        "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bam")
    output:
        os.path.join(
        cfg.processedDataDir,
        "rnaVariantCalling/out/bqsr",
        "{sample}_recal.table")
    params:
        ref = cfg.getFastaFile(),
        known_sites =  ["--known-sites " + i for i in cfg.RVC.get("knownVCFs")],
        outDir = cfg.processedDataDir / "rnaVariantCalling"
    log:
        cfg.processedDataDir / "logs/bqsr/{sample}.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" BaseRecalibrator -I {input} -R {params.ref} \
        {params.known_sites} -O {output} 2> {log}
        """


#Using GATK splitNCigarReads make use of the RNA splicing characteristic by mapping reads with large gaps to the reference. Split the RNAseq reads into subsections that will have better local alignments
rule rnaVariantCalling_splitNcigar:
    input:
        bam = os.path.join(
        cfg.processedDataDir, 
        "rnaVariantCalling/out/bam", 
        "{sample}", 
        "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bam")
    output:
        temp(os.path.join(
        cfg.processedDataDir, 
        "rnaVariantCalling/out/bam", 
        "{sample}", 
        "{sample}_Aligned.sortedByCoord.dupMarked.split.out.bam"))
    params:
        ref = cfg.getFastaFile(),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling"
    log:
        str(cfg.processedDataDir) + "/logs/splitNcigar/{sample}.log"
    shell:
        """
        gatk --java-options "-Djava.io.tmpdir={params.outDir}/tmp" SplitNCigarReads \
        -R {params.ref} -I {input.bam} -fixNDN \
        -O {output} 2> {log}
        #-RMQT 60 -U ALLOW_N_CIGAR_READS --allow_potentially_misencoded_quality_scores 2> {log}
        """

# Using picard ReorderSam the bam files so that they match the reference genome order.
rule rnaVariantCalling_reorderBAM:
    input:
        bam = os.path.join(
        cfg.processedDataDir, 
        "rnaVariantCalling/out/bam", 
        "{sample}", 
        "{sample}_Aligned.sortedByCoord.dupMarked.out.bam"),
    output:
        bam = temp(os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bam"
            )),
        bai = temp(os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bam.bai"))
    params:
        tmp_bai = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_Aligned.sortedByCoord.dupMarked.FAorder.out.bai"),
        ref = cfg.getFastaFile(),
        ref_dict = cfg.getFastaDict() # remove me for gatk 4.0.4.0
    shell:
        """
        echo "Create Sequence Dictionary"
        if [ ! -f "{params.ref_dict}" ]; then
            gatk CreateSequenceDictionary -R {params.ref} 
        fi
        echo "ReorderSam"
        gatk ReorderSam -I {input.bam} -O {output.bam} --SEQUENCE_DICTIONARY {params.ref_dict} -S true --CREATE_INDEX true # remove me for gatk4.0.4.0
        #gatk ReorderSam -I {input.bam} -O {output.bam} -R {params.ref} -S true --CREATE_INDEX true #use for gatk 4.0.4.0
        echo "mv {params.tmp_bai} {output.bai}"
        mv {params.tmp_bai} {output.bai}
        """

#Using GATK markDuplicates attempt to identify reads that are technical duplicates of biological reads. Attempts to eliminate noise introduced by library prep
rule rnaVariantCalling_markDuplicates:
    input:
        bam = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_Aligned.sortedByCoord.out.bam"),
        bai = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_Aligned.sortedByCoord.out.bam.bai")
    output:
        temp(os.path.join(
        cfg.processedDataDir, 
        "rnaVariantCalling/out/bam", 
        "{sample}", 
        "{sample}_Aligned.sortedByCoord.dupMarked.out.bam"))
    params:
        metrics = os.path.join( cfg.processedDataDir, "rnaVariantCalling/out/picard-tools-marked-dup-metrics.txt"),
        outDir = str(cfg.processedDataDir) + "/rnaVariantCalling"
    log:
        str(cfg.processedDataDir) + "/logs/markDuplicates/{sample}.log"
    shell:
        """
        echo {input.bam}
        gatk MarkDuplicates -I {input.bam} -O {output} \
        -M {params.metrics} --CREATE_INDEX true \
        --TMP_DIR "{params.outDir}/tmp" \
        --VALIDATION_STRINGENCY SILENT 2> {log}
        """


#Using samtools sort the reads based on their chromosomal coordinates
rule rnaVariantCalling_sortBam:
    input:
        bam = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_dropHeader.bam"),
        bai = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_dropHeader.bam.bai")
    output:
        bam = temp(os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_Aligned.sortedByCoord.out.bam")),
        bai = temp(os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_Aligned.sortedByCoord.out.bam.bai"))
    log:
        str(cfg.processedDataDir) + "/logs/sortBam/{sample}.log"

    shell:
        """
        samtools sort {input.bam} -O BAM -o {output.bam} &> {log}
        samtools index -b {output.bam}
        """


rule rnaVariantCalling_changeHeader:
    input:
        bam = str(cfg.processedDataDir) + "/bam_file_links/{sample}.bam",
        bai = str(cfg.processedDataDir) + "/bam_file_links/{sample}.bam.bai"
    output:
        bam = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_dropHeader.bam"),
        bai = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_dropHeader.bam.bai"),
        newHeader = os.path.join(
            cfg.processedDataDir, 
            "rnaVariantCalling/out/bam", 
            "{sample}", 
            "{sample}_newDropHeader.txt")
    params:
        tab = "\\t",
        newLine = "\\n",
        sedRef = "\\2"
    shell:
        """
        samtools view -H {input} |grep "^@RG" |grep SM |head -1|
        while read header ; do
            {{ for i in $header; do 
                 if [[ $i == "SM:"* ]]; then 
                    internalHeader=${{i:3}};
                    break
                else
                   internalHeader="";
                fi; 
            done; }}

            if [[ $internalHeader == {wildcards.sample} ]]; then
                echo "Internal Header $internalHeader matches {wildcards.sample}"
		ln -s  {input.bam} {output.bam}
                ln -s  {input.bai} {output.bai}
                touch {output.newHeader}
                echo "Done Linking files"
            else 
                echo "WARNING"
                echo "\tInternal Header is designated: $internalHeader";
                echo "\tSampleID is {wildcards.sample}"
                echo "\tForcing $internalHeader to match {wildcards.sample}"

               samtools view -H {input.bam} > {output.newHeader}
               echo 'sed -E -i "s/(SM:[^{params.tab}|{params.newLine}]*)({params.tab}|{params.newLine}*)/SM:{wildcards.sample}{params.sedRef}/" {output.newHeader}'
               # sed using regEx in place substitiute 'SM:' followed by any thing that isn't tab or newLine. and then replace it with the sampleID and the delimiter (tab or newLine) that matched in the 1st expression.
               sed -E -i "s/(SM:[^{params.tab}|{params.newLine}]*)({params.tab}|{params.newLine}*)/SM:{wildcards.sample}{params.sedRef}/" {output.newHeader}

               samtools reheader {output.newHeader} {input.bam} > {output.bam}

               samtools index -b {output.bam}

            fi
        done;
        """



#Using samtools index the bam files if they are not already indexed, and create a soft link to the working directory for easier access
rule rnaVariantCalling_indexReads:
    input:
        lambda wildcards: sa.getFilePath(wildcards.sample, "RNA_BAM_FILE")
    output:
        bam = str(cfg.processedDataDir) + "/bam_file_links/{sample}.bam",
        bai = str(cfg.processedDataDir) + "/bam_file_links/{sample}.bam.bai"
    log:
        str(cfg.processedDataDir) + "/logs/indexReads/{sample}.log"
    shell:
        """
        if [ ! -f "{input}.bai" ]; then
            samtools index -b {input} 2> {log}
        fi
        ln -s {input} {output.bam}
        ln -s "{input}.bai" {output.bai}
        """

# MUST UNCOMMENT indexReads
#rule readGroups:
#    input:
#        lambda wildcards: sa.getFilePath(wildcards.sample, "RNA_BAM_FILE")
#    output:
#        bam = str(cfg.processedDataDir) + "/bam_file_links/{sample}.bam",
#        bai = str(cfg.processedDataDir) + "/bam_file_links/{sample}.bam.bai"
#    params:
#        sample = "{sample}" ,
#        tmp_bai = str(cfg.processedDataDir) + "/bam_file_links/{sample}.bai"
#    log:
#        str(cfg.processedDataDir) + "/logs/readGroups/{sample}.log"
#    shell:
#        """
#        picard AddOrReplaceReadGroups I={input} O={output.bam} SORT_ORDER=coordinate \
#            RGID=1 RGLB="BONN" RGPL=unknown RGPU=unit1 RGSM={params.sample} CREATE_INDEX=True &> {log}
#        mv {params.tmp_bai} {output.bai}
#        #"""


